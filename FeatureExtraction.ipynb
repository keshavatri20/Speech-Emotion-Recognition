{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group_20_Project_FeatureExtraction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocyk4f8Bqtsx"
      },
      "source": [
        "<h2><center>Group 20</center></h2>\n",
        "<h3><center>Jainit Patel - 201801172</center></h3>\n",
        "<h3><center>Raj Desai - 201801183</center></h3>\n",
        "<h3><center>Chirag Gupta - 201801188</center></h3>\n",
        "<h3><center>Meet Parmar - 201801195</center></h3>\n",
        "<h3><center>Raj Bhavsar - 201801437</center></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii06X4KPdFmo"
      },
      "source": [
        "# Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlDd0MZUJARs",
        "outputId": "868de470-f8de-4c14-d10d-4555e542441f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDTcOJq5QkJh"
      },
      "source": [
        "# Speech Emotion Recognition - Feature Extraction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Psuv3UPLaPR"
      },
      "source": [
        "# Import needed Libraries\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import librosa\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBpIgx9bkdgJ"
      },
      "source": [
        "### Load all files\n",
        "\n",
        "We will create our numpy array extracting Mel-frequency cepstral coefficients (MFCCs) while the classes to predict will be extracted from the name of the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s16XwP5LK8a3"
      },
      "source": [
        "# There are total 8 types of classes or emotions\n",
        "emotions={\n",
        "  '01':'neutral',\n",
        "  '02':'calm',\n",
        "  '03':'happy',\n",
        "  '04':'sad',\n",
        "  '05':'angry',\n",
        "  '06':'fear',\n",
        "  '07':'disgust',\n",
        "  '08':'surprised'\n",
        "}\n",
        "\n",
        "#defined tess emotions to test on TESS dataset only\n",
        "tess_emotions=['angry','disgust','fear','ps','happy','sad']\n",
        "\n",
        "##defined RAVDESS emotions to test on RAVDESS dataset only\n",
        "ravdess_emotions=['neutral','calm','angry', 'happy','disgust','sad','fear','surprised']\n",
        "\n",
        "observed_emotions = ['sad','angry','happy','disgust','surprised','neutral','calm','fear']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOY5DJH5QkJu"
      },
      "source": [
        "#### Feature extraction\n",
        "\n",
        "Using librosa package we can extract the MFCC features. This function loads the file and after resampling and computing MFCC features, returns the features. We have selected the no. of MFCCs as 40."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9a81pkWLCs1"
      },
      "source": [
        "def extract_feature(file_name, mfcc):\n",
        "    # Loading audio file with default sample rate of sr=22050\n",
        "    X, sample_rate = librosa.load(os.path.join(file_name), res_type='kaiser_fast')\n",
        "    result = []\n",
        "    if mfcc:\n",
        "        mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0) # Averaging mfcc for same central frequency of all samples for same audio\n",
        "        result=np.hstack((result, mfccs)) \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA_pCop-QkJw"
      },
      "source": [
        "#### Choosing a dataset\n",
        "\n",
        "Choose the dataset(s) you want to load using the following function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN3E5vRNQkJw"
      },
      "source": [
        "# Choose dataset ravdess and tess\n",
        "\n",
        "def dataset_options():\n",
        "    \n",
        "    tess = True\n",
        "    ravdess_speech = True\n",
        "    ravdess_song = True\n",
        "    data = {'ravdess':ravdess, 'ravdess_speech':ravdess_speech, 'ravdess_song':ravdess_song, 'tess':tess}\n",
        "    print(data)\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYQw7zUZQkJx"
      },
      "source": [
        "#### Load data\n",
        "\n",
        "Load data from the datasets required which is obtained by calling the function dataset__options(). Extract features from each file with the selected emotions in chosen datasets using the extract_feature() function defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaV2hMcxLGZd"
      },
      "source": [
        "# How to access data from GDrive\n",
        "\n",
        "def load_data(test_size=0.2): \n",
        "    x,y=[],[]\n",
        "    \n",
        "    # feature to extract\n",
        "    mfcc = True\n",
        "    \n",
        "    data = dataset_options()\n",
        "    paths = []\n",
        "    \n",
        "    if data['ravdess_speech']:\n",
        "        paths.append(\"drive/MyDrive/ML/REVDESS_SPEECH/Actor_*/*.wav\")\n",
        "    elif data['ravdess_song']:\n",
        "        paths.append(\"drive/MyDrive/ML/REVDESS_SONG/Actor_*/*.wav\")\n",
        "        \n",
        "    for path in paths:\n",
        "        for file in glob.glob(path):\n",
        "            file_name=os.path.basename(file)\n",
        "            emotion=emotions[file_name.split(\"-\")[2]]  #extract emotion from filename. dictionary emotions is defined above.\n",
        "            if emotion not in observed_emotions:   #options observed_emotions - RAVDESS and TESS, ravdess_emotions for RAVDESS only\n",
        "                continue\n",
        "            feature=extract_feature(file, mfcc)\n",
        "            x.append(feature)\n",
        "            y.append(emotion)\n",
        "    if data['tess']:\n",
        "        for file in glob.glob(\"drive/MyDrive/ML/TESS/*AF_*.wav\"):\n",
        "            file_name=os.path.basename(file)\n",
        "            emotion=file_name.split(\"_\")[2][:-4] #split and remove .wav\n",
        "            # As discussed above, we will take plesently surprised and surprised in single class\n",
        "            if emotion == 'ps':\n",
        "                emotion = 'surprised'\n",
        "            if emotion not in observed_emotions: #options observed_emotions - RAVDESS and TESS, ravdess_emotions for RAVDESS only\n",
        "                continue\n",
        "            feature=extract_feature(file, mfcc)\n",
        "            x.append(feature)\n",
        "            y.append(emotion)\n",
        "    return {\"X\":x,\"y\":y}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVbx68UMLMAT",
        "outputId": "3a091818-5e9b-447b-809a-dcf56a2b7428"
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "Trial_dict = load_data(test_size = 0.3)\n",
        "\n",
        "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ravdess': False, 'ravdess_speech': True, 'ravdess_song': True, 'tess': True}\n",
            "--- Data loaded. Loading time: 2463.3275349140167 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WAO-j4iLPSn"
      },
      "source": [
        "X = pd.DataFrame(Trial_dict[\"X\"])\n",
        "y = pd.DataFrame(Trial_dict[\"y\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Huw2Md1XLQZm",
        "outputId": "fcb29148-5919-4669-f14f-ef329fffed37"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4240, 40), (4240, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpStckrSQkJ0"
      },
      "source": [
        "#renaming the label column to emotion\n",
        "y=y.rename(columns= {0: 'emotion'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08hSHcQyQkJ1"
      },
      "source": [
        "#concatinating the attributes and label or emotion into a single dataframe\n",
        "data = pd.concat([X, y], axis =1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xosdB5LwQkJ2"
      },
      "source": [
        "## Shuffling data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipRJsDyNQkJ2"
      },
      "source": [
        "#reindexing to shuffle the data at random\n",
        "data = data.reindex(np.random.permutation(data.index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp0fS7e8QkJ2"
      },
      "source": [
        "# Storing shuffled ravdess and tess data to avoid loading again\n",
        "data.to_csv(\"drive/MyDrive/ML/RAVTESS_MFCC_Observed.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}